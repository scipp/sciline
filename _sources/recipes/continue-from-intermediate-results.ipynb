{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Continue from intermediate results\n",
    "\n",
    "It is a common need to be able to continue the pipeline from some intermediate result computed earlier.\n",
    "\n",
    "TLDR\n",
    "```python\n",
    "# Pipeline: Input -> CleanData -> Result\n",
    "data = pipeline.compute(CleanData)\n",
    "pipeline[CleanData] = data\n",
    "result = pipeline.compute(Result)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Lets look at a situation where we have some \"raw\" data files and the workflow consists of three steps\n",
    "  * loading the raw data\n",
    "  * cleaning the raw data\n",
    "  * computing a sum of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NewType\n",
    "\n",
    "Filename = NewType('Filename', str)\n",
    "RawData = NewType('RawData', list)\n",
    "CleanData = NewType('CleanData', list)\n",
    "Result = NewType('Result', list)\n",
    "\n",
    "filesystem = {'raw.txt': list(map(str, range(10)))}\n",
    "\n",
    "def load(filename: Filename) -> RawData:\n",
    "    \"\"\"Load the data from the filename.\"\"\"\n",
    "    data = filesystem[filename]\n",
    "    return RawData(data)\n",
    "\n",
    "def clean(raw_data: RawData) -> CleanData:\n",
    "    \"\"\"Clean the data, convert from str.\"\"\"\n",
    "    return CleanData(list(map(float, raw_data)))\n",
    "\n",
    "def process(clean_data: CleanData) -> Result:\n",
    "    \"\"\"Compute the sum of the clean data.\"\"\"\n",
    "    return Result(sum(clean_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sciline\n",
    "\n",
    "pipeline = sciline.Pipeline(\n",
    "    [load, clean, process,],\n",
    "    params={ Filename: 'raw.txt', })\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Setting intermediate results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Given a pipeline, we may want to compute an intermediate result for inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pipeline.compute(CleanData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "If later on we wish to compute a result further down the pipeline (derived from `CleanData`), this would cause potentially costly re-computation of `CleanData`, since Sciline does not perform any caching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.compute(Result)  # re-computes CleanData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "To avoid this, we can use `Pipeline.__setitem__` to replace the provider of `CleanData` by the previously computed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline[CleanData] = data\n",
    "result = pipeline.compute(Result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
