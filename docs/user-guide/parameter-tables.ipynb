{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tables\n",
    "\n",
    "## Overview\n",
    "\n",
    "Sciline supports a mechanism for repeating parts of or all of a computation with different values for one or more parameters.\n",
    "This allows for a variety of use cases, similar to *map*, *reduce*, and *groupby* operations in other systems.\n",
    "We illustrate each of these in the follow three chapters.\n",
    "Sciline's implementation is based on [Cyclebane](https://scipp.github.io/cyclebane/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing results for series of parameters\n",
    "\n",
    "This chapter illustrates how to perform *map* operations with Sciline.\n",
    "\n",
    "Starting with the model workflow introduced in [Getting Started](getting-started.ipynb), we would like to replace the fixed `Filename` parameter with a series of filenames listed in a \"parameter table\".\n",
    "We begin by defining the base pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NewType\n",
    "import sciline\n",
    "\n",
    "_fake_filesytem = {\n",
    "    'file102.txt': [1, 2, float('nan'), 3],\n",
    "    'file103.txt': [1, 2, 3, 4],\n",
    "    'file104.txt': [1, 2, 3, 4, 5],\n",
    "    'file105.txt': [1, 2, 3],\n",
    "}\n",
    "\n",
    "# 1. Define domain types\n",
    "\n",
    "Filename = NewType('Filename', str)\n",
    "RawData = NewType('RawData', dict)\n",
    "CleanedData = NewType('CleanedData', list)\n",
    "ScaleFactor = NewType('ScaleFactor', float)\n",
    "Result = NewType('Result', float)\n",
    "\n",
    "\n",
    "# 2. Define providers\n",
    "\n",
    "\n",
    "def load(filename: Filename) -> RawData:\n",
    "    \"\"\"Load the data from the filename.\"\"\"\n",
    "\n",
    "    data = _fake_filesytem[filename]\n",
    "    return RawData({'data': data, 'meta': {'filename': filename}})\n",
    "\n",
    "\n",
    "def clean(raw_data: RawData) -> CleanedData:\n",
    "    \"\"\"Clean the data, removing NaNs.\"\"\"\n",
    "    import math\n",
    "\n",
    "    return CleanedData([x for x in raw_data['data'] if not math.isnan(x)])\n",
    "\n",
    "\n",
    "def process(data: CleanedData, param: ScaleFactor) -> Result:\n",
    "    \"\"\"Process the data, multiplying the sum by the scale factor.\"\"\"\n",
    "    return Result(sum(data) * param)\n",
    "\n",
    "\n",
    "# 3. Create pipeline\n",
    "\n",
    "providers = [load, clean, process]\n",
    "params = {ScaleFactor: 2.0}\n",
    "base = sciline.Pipeline(providers, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from not having defined a value for the `Filename` parameter, this is identical to the example in [Getting Started](getting-started.ipynb).\n",
    "The task-graph visualization indicates this missing parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.visualize(Result, graph_attr={'rankdir': 'LR'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a \"parameter table\" listing the filenames we would like to process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "run_ids = [102, 103, 104, 105]\n",
    "filenames = [f'file{i}.txt' for i in run_ids]\n",
    "param_table = pd.DataFrame({Filename: filenames}, index=run_ids).rename_axis(\n",
    "    index='run_id'\n",
    ")\n",
    "param_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we used a node name of the pipeline as the column name in the parameter table.\n",
    "For convenience we used a `pandas.DataFrame` to represent the table above, but the use of Pandas is entirely optional.\n",
    "Equivalently the table could be represented as a `dict`, where each key corresponds to a column header and each value is a list of values for that column, i.e., `{Filename: filenames}`.\n",
    "Specifying an index is currently not possible in this case, and it will default to a range index.\n",
    "\n",
    "We can now use [Pipeline.map](../generated/classes/sciline.Pipeline.rst#sciline.Pipeline.map) to create a modified pipeline that processes each row in the parameter table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = base.map(param_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the [compute_mapped](../generated/functions/sciline.compute_mapped.rst) function to compute `Result` for each index in the parameter table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sciline.compute_mapped(pipeline, Result)\n",
    "pd.DataFrame(results)  # DataFrame for HTML rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the use of the `run_id` index.\n",
    "If the index axis of the DataFrame has no name then a default of `dim_0`, `dim_1`, etc. is used.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**\n",
    "\n",
    "[compute_mapped](../generated/functions/sciline.compute_mapped.rst) depends on Pandas, which is not a dependency of Sciline and must be installed separately, e.g., using pip:\n",
    "\n",
    "```bash\n",
    "pip install pandas\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "We can also visualize the task graph for computing the series of `Result` values.\n",
    "For this, we need to get all the node names derived from `Result` via the `map` operation.\n",
    "The [get_mapped_node_names](../generated/functions/sciline.get_mapped_node_names.rst) function can be used to get a `pandas.Series` of these node names, which we can then visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = sciline.get_mapped_node_names(pipeline, Result)\n",
    "pipeline.visualize(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes that depend on values from a parameter table are drawn with the parameter index name (the row dimension of the parameter table) and index value (defaulting to a range index starting at 0 if no index if given) shown in parenthesis.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "With long parameter tables, graphs can get messy and hard to read.\n",
    "Try using `visualize(..., compact=True)`.\n",
    "\n",
    "The `compact=True` option to yields a much more compact representation.\n",
    "Instead of drawing every intermediate result and provider for each parameter, we then represent each parameter-dependent result as a single \"3D box\" node, representing all nodes for different values of the respective parameter.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining intermediate results from series of parameters\n",
    "\n",
    "This chapter illustrates how to implement *reduce* operations with Sciline.\n",
    "\n",
    "Instead of requesting a series of results as above, we use the [Pipeline.reduce](../generated/classes/sciline.Pipeline.rst#sciline.Pipeline.reduce) method and pass a function that combines the results from each parameter into a single result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pipeline.reduce(func=lambda *result: sum(result), name='merged').get('merged')\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**\n",
    "\n",
    "The `func` passed to `reduce` is *not* making use of Sciline's mechanism of assembling a graph based on type hints.\n",
    "In particular, the input type may be identical to the output type.\n",
    "The [Pipeline.reduce](../generated/classes/sciline.Pipeline.rst#sciline.Pipeline.reduce) method adds a *new* node, attached at a unique (but mapped) sink node of the graph.\n",
    "[Pipeline.__getitem__](../generated/classes/sciline.Pipeline.rst) and [Pipeline.__setitem__](../generated/classes/sciline.Pipeline.rst) can be used to compose more complex graphs where the reduction is not the final step.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the graph shown above is identical to the example in the previous section, except for the last two nodes in the graph.\n",
    "The computation now returns a single result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful if we need to continue computation after gathering results without setting up a second pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**\n",
    "\n",
    "For the `reduce` operation, all inputs to the reduction function have to be kept in memory simultaneously.\n",
    "This can be very memory intensive.\n",
    "We intend to support, e.g., hierarchical reduction operations in the future, where intermediate results are combined in a tree-like fashion to avoid excessive memory consumption..\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping intermediate results based on secondary parameters\n",
    "\n",
    "**Cyclebane and Sciline do not support `groupby` yet, this is work in progress so this example is not functional yet.**\n",
    "\n",
    "This chapter illustrates how to implement *groupby* operations with Sciline.\n",
    "\n",
    "Continuing from the examples for *map* and *reduce*, we can introduce a secondary parameter in the table, such as the material of the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Material = NewType('Material', str)\n",
    "\n",
    "run_ids = [102, 103, 104, 105]\n",
    "sample = ['diamond', 'graphite', 'graphite', 'graphite']\n",
    "filenames = [f'file{i}.txt' for i in run_ids]\n",
    "param_table = pd.DataFrame(\n",
    "    {Filename: filenames, Material: sample}, index=run_ids\n",
    ").rename_axis(index='run_id')\n",
    "param_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future releases of Sciline will support a `groupby` operation, roughly as follows:\n",
    "\n",
    "```python\n",
    "pipeline = base.map(param_table).groupby(Material).reduce(func=merge)\n",
    "```\n",
    "\n",
    "We can then compute the merged result, grouped by the value of `Material`.\n",
    "Note how the initial steps of the computation depend on the `run_id` index name, while later steps depend on `Material`, a new index name defined by the `groupby` operation.\n",
    "The files for each run ID have been grouped by their material and then merged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining multiple parameters from same table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sciline as sl\n",
    "\n",
    "Sum = NewType(\"Sum\", float)\n",
    "Param1 = NewType(\"Param1\", int)\n",
    "Param2 = NewType(\"Param2\", int)\n",
    "\n",
    "\n",
    "def gather(*x: float) -> Sum:\n",
    "    return Sum(sum(x))\n",
    "\n",
    "\n",
    "def product(x: Param1, y: Param2) -> float:\n",
    "    return x / y\n",
    "\n",
    "\n",
    "params = pd.DataFrame({Param1: [1, 4, 9], Param2: [1, 2, 3]})\n",
    "pl = sl.Pipeline([product])\n",
    "pl = pl.map(params).reduce(func=gather, name=Sum)\n",
    "\n",
    "pl.visualize(Sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.compute(Sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diamond graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sum = NewType(\"Sum\", float)\n",
    "Param = NewType(\"Param\", int)\n",
    "Param1 = NewType(\"Param1\", int)\n",
    "Param2 = NewType(\"Param2\", int)\n",
    "\n",
    "\n",
    "def gather(*x: float) -> float:\n",
    "    return sum(x)\n",
    "\n",
    "\n",
    "def to_param1(x: Param) -> Param1:\n",
    "    return Param1(x)\n",
    "\n",
    "\n",
    "def to_param2(x: Param) -> Param2:\n",
    "    return Param2(x)\n",
    "\n",
    "\n",
    "def product(x: Param1, y: Param2) -> float:\n",
    "    return x * y\n",
    "\n",
    "\n",
    "pl = sl.Pipeline([product, to_param1, to_param2])\n",
    "params = pd.DataFrame({Param: [1, 2, 3]})\n",
    "pl = pl.map(params).reduce(func=gather, name=Sum)\n",
    "pl.visualize(Sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining parameters from different tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import sciline as sl\n",
    "\n",
    "Param1 = NewType(\"Param1\", int)\n",
    "Param2 = NewType(\"Param2\", int)\n",
    "\n",
    "\n",
    "def gather(*x: Any) -> list[Any]:\n",
    "    return list(x)\n",
    "\n",
    "\n",
    "def product(x: Param1, y: Param2) -> float:\n",
    "    return x * y\n",
    "\n",
    "\n",
    "base = sl.Pipeline([product])\n",
    "pl = (\n",
    "    base.map({Param1: [1, 4, 9]})\n",
    "    .map({Param2: [1, 2]})\n",
    "    .reduce(func=gather, name='reduce_1', index='dim_1')\n",
    "    .reduce(func=gather, name='reduce_0')\n",
    ")\n",
    "\n",
    "pl.visualize('reduce_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how intermediates such as `float(dim_1, dim_0)` depend on two parameters, i.e., we are dealing with a 2-D array of branches in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.compute('reduce_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to reduce multiple axes at once.\n",
    "For example, `reduce` will reduce all axes if no `index` or `axis` is specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = (\n",
    "    base.map({Param1: [1, 4, 9]})\n",
    "    .map({Param2: [1, 2]})\n",
    "    .reduce(func=gather, name='reduce_both')\n",
    ")\n",
    "pl.visualize('reduce_both')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
